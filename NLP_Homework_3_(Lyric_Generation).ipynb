{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Homework #3 (Lyric Generation).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjung2-oxy/Natural-Lang-Processing/blob/main/NLP_Homework_3_(Lyric_Generation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBqANLjnN6BR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ec2e05-165b-4413-f823-8664c7f37686"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y22Fx03KzZU"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import io\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATI6lVG9KjmM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "0033bf8f-05d7-4879-9c2c-cf7fb24ee6a8"
      },
      "source": [
        "# Import Lyrics\n",
        "country_lyrics = { \"Song Name\": [], \"Lyrics\": []}\n",
        "metal_lyrics = { \"Song Name\": [], \"Lyrics\": []}\n",
        "pop_lyrics = { \"Song Name\": [], \"Lyrics\": []}\n",
        "rock_lyrics = { \"Song Name\": [], \"Lyrics\": []}\n",
        "\n",
        "# Get Country Lyrics\n",
        "country_directory = r'/content/drive/MyDrive/Homework3-Data/Homework 3 Data/Country'\n",
        "\n",
        "for file in os.listdir(country_directory):\n",
        "    f = os.path.join(country_directory, file)\n",
        "    filename = os.path.splitext(file)[0]\n",
        "\n",
        "    if os.path.isfile(f) and file.endswith('.txt'):\n",
        "      with open(f, encoding='utf-8') as text:\n",
        "          contents = text.read()\n",
        "          country_lyrics[\"Song Name\"].append(filename)\n",
        "          country_lyrics[\"Lyrics\"].append(contents)\n",
        "\n",
        "# Turn dict into DataFrame, print first 5 songs\n",
        "country_df = pd.DataFrame(country_lyrics)\n",
        "country_df.head(5)\n",
        "\n",
        "# Get Metal Lyrics\n",
        "metal_directory = r'/content/drive/MyDrive/Homework3-Data/Homework 3 Data/Metal'\n",
        "\n",
        "for file in os.listdir(metal_directory):\n",
        "    f = os.path.join(metal_directory, file)\n",
        "    filename = os.path.splitext(file)[0]\n",
        "\n",
        "    if os.path.isfile(f) and file.endswith('.txt'):\n",
        "      with open(f, encoding='utf-8') as text:\n",
        "          contents = text.read()\n",
        "          metal_lyrics[\"Song Name\"].append(filename)\n",
        "          metal_lyrics[\"Lyrics\"].append(contents)\n",
        "\n",
        "# Turn dict into DataFrame, print first 5 songs\n",
        "metal_df = pd.DataFrame(metal_lyrics)\n",
        "metal_df.head(5)\n",
        "\n",
        "# Get Pop Lyrics\n",
        "pop_directory = r'/content/drive/MyDrive/Homework3-Data/Homework 3 Data/Pop'\n",
        "\n",
        "for file in os.listdir(pop_directory):\n",
        "    f = os.path.join(pop_directory, file)\n",
        "    filename = os.path.splitext(file)[0]\n",
        "\n",
        "    if os.path.isfile(f) and file.endswith('.txt'):\n",
        "      with open(f, encoding='utf-8') as text:\n",
        "          contents = text.read()\n",
        "          pop_lyrics[\"Song Name\"].append(filename)\n",
        "          pop_lyrics[\"Lyrics\"].append(contents)\n",
        "\n",
        "# Turn dict into DataFrame, print first 5 songs\n",
        "pop_df = pd.DataFrame(pop_lyrics)\n",
        "pop_df.head(5)\n",
        "\n",
        "# Get Rock Lyrics\n",
        "rock_directory = r'/content/drive/MyDrive/Homework3-Data/Homework 3 Data/Rock'\n",
        "\n",
        "for file in os.listdir(rock_directory):\n",
        "    f = os.path.join(rock_directory, file)\n",
        "    filename = os.path.splitext(file)[0]\n",
        "\n",
        "    if os.path.isfile(f) and file.endswith('.txt'):\n",
        "      with open(f, encoding='utf-8') as text:\n",
        "          contents = text.read()\n",
        "          rock_lyrics[\"Song Name\"].append(filename)\n",
        "          rock_lyrics[\"Lyrics\"].append(contents)\n",
        "\n",
        "# Turn dict into DataFrame, print first 5 songs\n",
        "rock_df = pd.DataFrame(rock_lyrics)\n",
        "rock_df.head(5)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Song Name</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's Up</td>\n",
              "      <td>25 years of my life and still\\nI'm trying to g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sweet Child O' Mine</td>\n",
              "      <td>She's got a smile that it seems to me\\nReminds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T.N.T</td>\n",
              "      <td>See me ride out of the sunset\\nOn your colour ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Caught Up In You</td>\n",
              "      <td>I never knew there'd come a day\\nWhen I'd be s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lucky</td>\n",
              "      <td>Do you hear me,\\nI'm talking to you\\nAcross th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Song Name                                             Lyrics\n",
              "0            What's Up  25 years of my life and still\\nI'm trying to g...\n",
              "1  Sweet Child O' Mine  She's got a smile that it seems to me\\nReminds...\n",
              "2                T.N.T  See me ride out of the sunset\\nOn your colour ...\n",
              "3     Caught Up In You  I never knew there'd come a day\\nWhen I'd be s...\n",
              "4                Lucky  Do you hear me,\\nI'm talking to you\\nAcross th..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYZU7SQKHwz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "ff8b63a4-22a2-45bc-d33b-e76b7b9fd5c3"
      },
      "source": [
        "# Data Pre-Processing\n",
        "def clean_lyrics(x):\n",
        "    x = x[\"Lyrics\"]\n",
        "\n",
        "    # Turn to lowercase\n",
        "    x = x.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    x = \"\".join([char for char in x if char not in string.punctuation])\n",
        "\n",
        "    # Convert into Pandas series\n",
        "    processed_lyrics = pd.Series(data=x)\n",
        "    \n",
        "    return processed_lyrics\n",
        "\n",
        "# Pre-process country lyrics\n",
        "processed_lyrics = country_df.apply(clean_lyrics, axis=1, result_type='expand')\n",
        "country_df[\"Processed Lyrics\"] = processed_lyrics\n",
        "country_df.head(5)\n",
        "\n",
        "# Pre-process metal lyrics\n",
        "processed_lyrics = metal_df.apply(clean_lyrics, axis=1, result_type='expand')\n",
        "metal_df[\"Processed Lyrics\"] = processed_lyrics\n",
        "metal_df.head(5)\n",
        "\n",
        "# Pre-process pop lyrics\n",
        "processed_lyrics = pop_df.apply(clean_lyrics, axis=1, result_type='expand')\n",
        "pop_df[\"Processed Lyrics\"] = processed_lyrics\n",
        "pop_df.head(5)\n",
        "\n",
        "# Pre-process rock lyrics\n",
        "processed_lyrics = rock_df.apply(clean_lyrics, axis=1, result_type='expand')\n",
        "rock_df[\"Processed Lyrics\"] = processed_lyrics\n",
        "rock_df.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Song Name</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>Processed Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's Up</td>\n",
              "      <td>25 years of my life and still\\nI'm trying to g...</td>\n",
              "      <td>25 years of my life and still\\nim trying to ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sweet Child O' Mine</td>\n",
              "      <td>She's got a smile that it seems to me\\nReminds...</td>\n",
              "      <td>shes got a smile that it seems to me\\nreminds ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T.N.T</td>\n",
              "      <td>See me ride out of the sunset\\nOn your colour ...</td>\n",
              "      <td>see me ride out of the sunset\\non your colour ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Caught Up In You</td>\n",
              "      <td>I never knew there'd come a day\\nWhen I'd be s...</td>\n",
              "      <td>i never knew thered come a day\\nwhen id be say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lucky</td>\n",
              "      <td>Do you hear me,\\nI'm talking to you\\nAcross th...</td>\n",
              "      <td>do you hear me\\nim talking to you\\nacross the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Song Name  ...                                   Processed Lyrics\n",
              "0            What's Up  ...  25 years of my life and still\\nim trying to ge...\n",
              "1  Sweet Child O' Mine  ...  shes got a smile that it seems to me\\nreminds ...\n",
              "2                T.N.T  ...  see me ride out of the sunset\\non your colour ...\n",
              "3     Caught Up In You  ...  i never knew thered come a day\\nwhen id be say...\n",
              "4                Lucky  ...  do you hear me\\nim talking to you\\nacross the ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOoHmRlksJjU"
      },
      "source": [
        "# Indexes words in word_indices(word:index) and indices_word(index:word) format, and gets vocabulary (words) and number of unique words (vocab_size)\n",
        "\n",
        "def generate_dict_data(text):\n",
        "    word_to_index= dict() # Dict {word: integer}\n",
        "    index_to_word = dict()  # Dict {integer: word}\n",
        "    corpus = [] # All words in the lyrics\n",
        "    \n",
        "    # Create corpus of ALL words (not-unique)\n",
        "    for row in text:\n",
        "        lines = row.split('\\n')\n",
        "\n",
        "        for line in lines:\n",
        "            # add newline as seperate word to each line \n",
        "            line  = line + \" \\n \"\n",
        "            for word in line.split(\" \"):\n",
        "                if word != '':\n",
        "                    corpus.append(word)\n",
        "    print(corpus)\n",
        "\n",
        "    # Create vocabulary of unique words from corpus\n",
        "    print(f\"Size of corpus: {len(corpus)}\")\n",
        "    words = set(corpus)\n",
        "    vocab_size = len(words)\n",
        "    print(f\"Size of vocabulary: {vocab_size}\")\n",
        "\n",
        "    # Create word indices\n",
        "    word_indices = dict((c, i) for i, c in enumerate(words))\n",
        "    indices_word = dict((i, c) for i, c in enumerate(words))\n",
        "\n",
        "    return word_indices, indices_word, words, vocab_size, corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQz-_uAGLrad"
      },
      "source": [
        "# Turns lyrics into list of lists of words [[lyric_word1, lyric_word2, lyric_word3,...], [lyric2_word1, lyric2_word2, ...], ...]\n",
        "def lyrics_to_sentences(genre_df, corpus):\n",
        "    lyrics_in_sentences = []  # All sentences in lyrics\n",
        "    sentence = []   # One sentence in lyrics\n",
        "    lyrics_in_words = [] # Tokenized (word by word) lyrics\n",
        "\n",
        "    # Add word from corpus to list of sentences\n",
        "    for word in corpus:\n",
        "        if word == \"\\n\":\n",
        "            lyrics_in_words.append(word)\n",
        "            sentence.append(word)\n",
        "            # Add sentence to list of sentences\n",
        "            lyrics_in_sentences.append(sentence)\n",
        "            # Clear current sentence\n",
        "            sentence = []\n",
        "        elif word != '':\n",
        "            sentence.append(word)\n",
        "            lyrics_in_words.append(word)\n",
        "            \n",
        "    return lyrics_in_words, lyrics_in_sentences\n",
        "\n",
        "# Turn text into sequences of sequence_length (default=5) words\n",
        "def lyrics_to_sequence(genre_df, genre_corpus, sequence_length=5):\n",
        "    sequences = []\n",
        "    next_words = []\n",
        "\n",
        "    # Turn lyrics into all words and into seperate sentences.\n",
        "    lyrics_in_words, sentences = lyrics_to_sentences(genre_df, genre_corpus)\n",
        "\n",
        "    # For genre lyrics in words, create list of sequence_length sequences of words and list of the next word in the sequence\n",
        "    for i in range(0, len(lyrics_in_words) - sequence_length):\n",
        "        sequences.append(lyrics_in_words[i: i + sequence_length])\n",
        "        next_words.append(lyrics_in_words[i + sequence_length])\n",
        "\n",
        "    print('Total sequences:', len(sequences))\n",
        "    return sequences, next_words\n",
        "\n",
        "# Split sequences and next_words into training/testing input/output.\n",
        "def train_test(sequences, next_words):\n",
        "\n",
        "    # sequences (input), next_words (ouput)\n",
        "    sequences_train, sequences_test, next_words_train, next_words_test = train_test_split(sequences, next_words, test_size=0.2, random_state=42)\n",
        "    return sequences_train, sequences_test, next_words_train, next_words_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shfvPWUWEClV"
      },
      "source": [
        "# Create sequential model with word embedding layer and LSTM layer. Dropout to prevent overfitting. \n",
        "def get_model(vocab_size, dropout=0.2):\n",
        "    # Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Embedding layer for word embedding\n",
        "    model.add(Embedding(input_dim= vocab_size, output_dim=1024))\n",
        "\n",
        "    # Bidirectional LSTM model with 128 nodes\n",
        "    model.add(Bidirectional(LSTM(128)))\n",
        "\n",
        "    # Dropout layer. Activated and set to 0.2 default.\n",
        "    if dropout > 0:\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Dense layer\n",
        "    model.add(Dense(vocab_size))\n",
        "\n",
        "    # Softmax Activation\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # Spare categorical b/c output is NOT one-hot encoded.\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujsOXM1drPrF"
      },
      "source": [
        "# generator function from keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
        "# Feeds neural network batches of inputs/outputs to prevent insufficient memory issues.\n",
        "def generator(sentence_list, next_word_list, batch_size, word_indices):\n",
        "    index = 0\n",
        "    SEQUENCE_LEN = 5\n",
        "\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, SEQUENCE_LEN), dtype=np.int32)\n",
        "        y = np.zeros((batch_size), dtype=np.int32)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
        "                x[i, t] = word_indices[w]\n",
        "      \n",
        "            y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n",
        "            index = index + 1\n",
        "        yield x, y\n",
        "\n",
        "# Train model with sequences as input and next_words as output to guess\n",
        "def fit_model(sequences_train, next_words_train, sequences_test, next_words_test, model, word_indices):\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # If loss stops improving after 3 epochs, stop learning early\n",
        "    callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "  \n",
        "    # Fit model. Use generator to feed neural network batches of input/output\n",
        "    model.fit(generator(sequences_train, next_words_train, BATCH_SIZE, word_indices),\n",
        "                    steps_per_epoch=int(len(sequences_train)/BATCH_SIZE) + 1,\n",
        "                    epochs=20,  \n",
        "                    callbacks=[callback],\n",
        "                    validation_data=generator(sequences_test, next_words_test, BATCH_SIZE, word_indices),\n",
        "                    validation_steps=int(len(sequences_test)/BATCH_SIZE) + 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLbq52i_t0wE"
      },
      "source": [
        "# sample function from keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
        "# Uses probability distributions to predict the next_word (doesn't choose best fitting word, chooses randomly while accounting for best fitting words)\n",
        "def sample(preds, temperature=1.0):\n",
        "    # Ensure list can be used as input\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "\n",
        "    # Puts predictions back into logspace. Temperature controls 'randomness' of model\n",
        "    preds = np.log(preds) / temperature\n",
        "\n",
        "    # Apply softmax\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # Sample one-hot vector \n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    \n",
        "    # Returns index of largest vector which correpsonds to a word in our vocabulary\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# Generates the first line of our lyric\n",
        "def generate_lyrics(model, indices_word, word_indices, seed, sequence_length, vocabulary, diversity):\n",
        "    sentence = seed\n",
        "    vocabulary_length = len(vocabulary)\n",
        "\n",
        "    # Prints the seed sentence as words\n",
        "    for word in sentence:\n",
        "        print(\" \"+word, end=\"\")\n",
        "\n",
        "    # Executes for 4 lines of generated lyrics. (5 total printed with above sentence)\n",
        "    newline_count = 0\n",
        "    while newline_count < 5:\n",
        "        x_pred = np.zeros((1, sequence_length))\n",
        "\n",
        "        for t, word in enumerate(sentence):\n",
        "            x_pred[0, t] = word_indices[word]\n",
        "\n",
        "        # Predict next word vector\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "        # Choose index from Conditional probability distribution\n",
        "        next_index = sample(preds, diversity)\n",
        "\n",
        "        # Find next_word by index\n",
        "        next_word = indices_word[next_index]\n",
        "\n",
        "        # Remove first word from sentence, add next_word\n",
        "        sentence = sentence[1:]\n",
        "        sentence.append(next_word)\n",
        "\n",
        "        # Count number of newlines generated\n",
        "        if next_word == '\\n':\n",
        "            newline_count = newline_count + 1\n",
        "\n",
        "        # Print generated word\n",
        "        print(\" \" + next_word, end=\"\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return next_word\n",
        "\n",
        "def generate_seed(genre_sequences):\n",
        "    # Generated random index\n",
        "    seed_index = random.randint(0, int(len(genre_sequences) - 1))\n",
        "\n",
        "    # Choose seed from genre sequences\n",
        "    seed = genre_sequences[seed_index]\n",
        "\n",
        "    # Take only the first 5 words of sequence       \n",
        "    seed = seed[0:5]\n",
        "        \n",
        "    return seed\n",
        "\n",
        "# Generate lyrics based on genre\n",
        "def print_lyrics(genre_sequences, model, genre_itw, genre_wti, genre_words):\n",
        "    \n",
        "    # Find random 5 word sequence to base the generation on\n",
        "    seed = generate_seed(genre_sequences)\n",
        "\n",
        "    # Generate the lyrics\n",
        "    generate_lyrics(model, genre_itw, genre_wti, seed, sequence_length=5, vocabulary=genre_words, diversity=.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxqb7yg6YH7g"
      },
      "source": [
        "# PREPARE WORD INDEXES, WORD SENTENCES, AND SPLIT DATA INTO TRAINING AND TESTING\n",
        "\n",
        "print(\"Preparing Country Lyrics:\")\n",
        "country_wti, country_itw, country_words, country_length, country_corpus = generate_dict_data(country_df[\"Processed Lyrics\"])\n",
        "country_sequences, country_nextwords = lyrics_to_sequence(country_df, country_corpus)\n",
        "country_sequence_train, country_sequence_test, country_nextword_train, country_nextword_test = train_test(country_sequences, country_nextwords)\n",
        "print(country_sequences)\n",
        "print(country_nextwords)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Preparing Metal lyrics:\")\n",
        "metal_wti, metal_itw, metal_words, metal_length, metal_corpus = generate_dict_data(metal_df[\"Processed Lyrics\"])\n",
        "metal_sequences, metal_nextwords = lyrics_to_sequence(metal_df, metal_corpus)\n",
        "metal_sequence_train, metal_sequence_test, metal_nextword_train, metal_nextword_test = train_test(metal_sequences, metal_nextwords)\n",
        "print(metal_sequences)\n",
        "print(metal_nextwords)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Preparing Pop lyrics:\")\n",
        "pop_wti, pop_itw, pop_words, pop_length, pop_corpus = generate_dict_data(pop_df[\"Processed Lyrics\"])\n",
        "pop_sequences, pop_nextwords = lyrics_to_sequence(pop_df, pop_corpus)\n",
        "pop_sequence_train, pop_sequence_test, pop_nextword_train, pop_nextword_test = train_test(pop_sequences, pop_nextwords)\n",
        "print(pop_sequences)\n",
        "print(pop_nextwords)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Preparing Rock lyrics:\")\n",
        "rock_wti, rock_itw, rock_words, rock_length, rock_corpus = generate_dict_data(rock_df[\"Processed Lyrics\"])\n",
        "rock_sequences, rock_nextwords = lyrics_to_sequence(rock_df, rock_corpus)\n",
        "rock_sequence_train, rock_sequence_test, rock_nextword_train, rock_nextword_test = train_test(rock_sequences, rock_nextwords)\n",
        "print(rock_sequences)\n",
        "print(rock_nextwords)\n",
        "print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW81hBPF0gcn"
      },
      "source": [
        "print(\"CAUTION: LOADING MODELS DOES NOT WORK! NEWLY CREATED WORD INDICES WON'T BE ALIGNED TO LOADED MODEL...\")\n",
        "load_or_train_model = input(\"To train new models: 0, To load models: 1\")\n",
        "\n",
        "if load_or_train_model == '0':\n",
        "    train_country = input(\"Train country? y/n\")\n",
        "    if train_country == \"y\":\n",
        "        # COUNTRY MODEL CREATION/TRAINING/FITTING\n",
        "\n",
        "        # Instantiate (build) model\n",
        "        print(\"Building country model...\")\n",
        "        country_model_untrained = get_model(country_length)\n",
        "        country_model_untrained.summary()\n",
        "\n",
        "        # Fit (train) Model\n",
        "        country_model = fit_model(country_sequence_train, country_nextword_train, country_sequence_test, country_nextword_test, country_model_untrained, country_wti)\n",
        "\n",
        "        # Save Model\n",
        "        country_model.save('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/country_model')\n",
        "\n",
        "    train_metal = input(\"Train metal? y/n\")\n",
        "    if train_metal == \"y\":\n",
        "        # METAL MODEL CREATION/TRAINING/FITTING\n",
        "\n",
        "        # Instantiate (build) model\n",
        "        print(\"Building metal model...\")\n",
        "        metal_model_untrained = get_model(metal_length)\n",
        "        metal_model_untrained.summary()\n",
        "\n",
        "        # Fit (train) Model\n",
        "        metal_model = fit_model(metal_sequence_train, metal_nextword_train, metal_sequence_test, metal_nextword_test, metal_model_untrained, metal_wti)\n",
        "\n",
        "        # Save Model\n",
        "        metal_model.save('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/metal_model')\n",
        "\n",
        "    train_pop = input(\"Train pop? y/n\")\n",
        "    if train_pop == \"y\":\n",
        "        # POP MODEL CREATION/TRAININIG/FITTING\n",
        "\n",
        "        # Instantiate (build) Model\n",
        "        print(\"Building pop model...\")\n",
        "        pop_model_untrained = get_model(pop_length)\n",
        "        pop_model_untrained.summary()\n",
        "\n",
        "        # Fit (train) Model\n",
        "        pop_model = fit_model(pop_sequence_train, pop_nextword_train, pop_sequence_test, pop_nextword_test, pop_model_untrained, pop_wti)\n",
        "\n",
        "        # Save Model\n",
        "        pop_model.save('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/pop_model')\n",
        "\n",
        "    train_rock = input(\"Train rock? y/n\")\n",
        "    if train_rock == 'y':\n",
        "        # ROCK MODEL CREATION/TRAINING/FITTING\n",
        "\n",
        "        # Instantiate (build) Model\n",
        "        print(\"Building rock model...\")\n",
        "        rock_model_untrained = get_model(rock_length)\n",
        "        rock_model_untrained.summary()\n",
        "\n",
        "        # Fit (train) Model\n",
        "        rock_model = fit_model(rock_sequence_train, rock_nextword_train, rock_sequence_test, rock_nextword_test, rock_model_untrained, rock_wti)\n",
        "\n",
        "        # Save Model\n",
        "        rock_model.save('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/rock_model')\n",
        "\n",
        "else:\n",
        "    # Loading Models doesn't work for lyric generation... Pre-loaded Models won't be aligned with newly generated word indices...\n",
        "    # Load Country Model\n",
        "    print(\"Loading Country Model...\")\n",
        "    country_model = keras.models.load_model('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/country_model')\n",
        "\n",
        "    # Load Metal Model\n",
        "    print(\"Loading Metal Model...\")\n",
        "    metal_model = keras.models.load_model('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/metal_model')\n",
        "\n",
        "    # Load Pop Model\n",
        "    print(\"Loading Pop Model...\")\n",
        "    pop_model = keras.models.load_model('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/pop_model')\n",
        "\n",
        "    # Load Rock Model\n",
        "    print(\"Loading Rock Model...\")\n",
        "    rock_model = keras.models.load_model('/content/drive/MyDrive/Homework3-Data/Homework 3 Data/rock_model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_DE5S-k_Sa3"
      },
      "source": [
        "# Print Country Lyrics\n",
        "print(\"Generating country lyrics...\")\n",
        "print_lyrics(country_sequences, country_model, country_itw, country_wti, country_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLw4JTd8Cc4k"
      },
      "source": [
        "# Print metal lyrics\n",
        "print(\"Generating metal lyrics...\")\n",
        "metal_sentences = lyrics_to_words(metal_df)\n",
        "print_lyrics(metal_sentences, metal_model, metal_itw, metal_wti, metal_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taFyPM5qCk2Y"
      },
      "source": [
        "# Print Pop lyrics\n",
        "print(\"Generating pop lyrics...\")\n",
        "pop_sentences = lyrics_to_words(pop_df)\n",
        "print_lyrics(pop_sentences, pop_model, pop_itw, pop_wti, pop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YA8VbWDCqii"
      },
      "source": [
        "# Print rock lyrics\n",
        "print(\"Generating rock lyrics...\")\n",
        "rock_sentences = lyrics_to_words(rock_df)\n",
        "print_lyrics(rock_sentences, rock_model, rock_itw, rock_wti, rock_words)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}